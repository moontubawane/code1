    <title>The Global Translator 5000: Conversational Module</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
    <style>
        /* Custom styles for a professional and slightly futuristic look */
        .card {
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1), 0 4px 12px rgba(0, 0, 0, 0.05);
            transition: all 0.3s ease;
        }
        .card:hover {
            box-shadow: 0 15px 45px rgba(0, 0, 0, 0.15), 0 6px 18px rgba(0, 0, 0, 0.08);
        }
        /* Custom microphone button animation for visual feedback */
        .mic-button {
            transition: all 0.2s;
            position: relative;
        }
        .mic-button:hover {
            transform: scale(1.05);
            background-color: #10B981; /* Emerald 500 */
        }
        .mic-button.recording {
            animation: pulse-red 1.5s infinite;
            background-color: #EF4444; /* Red 500 */
            box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7);
        }
        @keyframes pulse-red {
            0% {
                transform: scale(0.95);
                box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7);
            }
            70% {
                transform: scale(1.0);
                box-shadow: 0 0 0 10px rgba(239, 68, 68, 0);
            }
            100% {
                transform: scale(0.95);
                box-shadow: 0 0 0 0 rgba(239, 68, 68, 0);
            }
        }
        /* Style the link for grounding sources */
        .source-link {
            color: #3B82F6;
            text-decoration: none;
            transition: color 0.2s;
        }
        .source-link:hover {
            color: #2563EB;
            text-decoration: underline;
        }
    </style>
<div class="bg-gray-50 flex items-center justify-center min-h-screen p-4 font-sans antialiased" style="font-family: 'Inter', sans-serif;">

    <!-- Main Application Container -->
    <div id="app-container" class="w-full max-w-2xl bg-white card rounded-xl p-8 shadow-xl border border-gray-100">

        <h1 class="text-4xl font-extrabold text-gray-800 text-center mb-2">
            The Global Translator 5000
        </h1>
        <p class="text-lg text-gray-500 text-center mb-8">
            Hindi-to-English Conversational Module (v2.1 Beta)
        </p>

        <!-- Status Display Area -->
        <div id="status-display" class="bg-blue-50 text-blue-700 p-4 rounded-lg mb-6 border border-blue-200 text-center text-sm font-medium transition duration-300">
            System Operational. Awaiting High-Value Audio Input.
        </div>

        <!-- Input Area (Microphone Button) -->
        <div class="flex flex-col items-center justify-center space-y-4 mb-8">
            <button id="mic-button"
                    class="mic-button bg-emerald-600 text-white w-24 h-24 rounded-full flex items-center justify-center focus:outline-none focus:ring-4 focus:ring-emerald-300 shadow-lg"
                    title="Press and speak in Hindi">
                <i class="fas fa-microphone text-3xl"></i>
            </button>
            <p id="mic-prompt" class="text-gray-600 font-semibold">
                Click to Initiate Audio Protocol
            </p>
        </div>

        <!-- Output Area -->
        <div class="space-y-6">
            <!-- Hindi Transcript Panel -->
            <div>
                <h2 class="text-xl font-bold text-gray-700 mb-2 border-b pb-1">
                    [SOURCE] Recognized Hindi Transcript
                </h2>
                <div id="hindi-transcript" class="min-h-16 bg-gray-50 p-4 rounded-lg text-gray-800 border border-gray-200 italic">
                    (Your esteemed voice input will appear here after analysis.)
                </div>
            </div>

            <!-- English Translation Panel -->
            <div>
                <h2 class="text-xl font-bold text-gray-700 mb-2 border-b pb-1">
                    [TARGET] Refined English Translation
                </h2>
                <div id="english-translation" class="min-h-24 bg-white p-4 rounded-lg text-gray-900 border-2 border-indigo-400 font-medium leading-relaxed">
                    (The system's high-value, professionally humorous output will be rendered here.)
                </div>
                <div id="sources-display" class="mt-2 text-xs text-gray-500 hidden">
                    <!-- Grounding sources will be inserted here if available -->
                </div>
            </div>
        </div>
    </div>

    <!-- Firebase and Application Logic -->
    <script type="module">
        // --- Mandatory Firebase Imports and Setup ---
        import { initializeApp } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-app.js";
        import { getAuth, signInAnonymously, signInWithCustomToken, onAuthStateChanged } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-auth.js";
        import { getFirestore, setLogLevel } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-firestore.js";

        // Global variables provided by the environment
        const appId = typeof __app_id !== 'undefined' ? __app_id : 'default-app-id';
        const firebaseConfig = typeof __firebase_config !== 'undefined' ? JSON.parse(__firebase_config) : null;
        const initialAuthToken = typeof __initial_auth_token !== 'undefined' ? __initial_auth_token : null;

        let db;
        let auth;
        let userId = null;
        let isAuthReady = false;

        setLogLevel('Debug'); // Enable Firestore logging

        if (firebaseConfig) {
            const app = initializeApp(firebaseConfig);
            db = getFirestore(app);
            auth = getAuth(app);

            // Authentication Setup
            onAuthStateChanged(auth, async (user) => {
                if (user) {
                    userId = user.uid;
                } else {
                    try {
                        // Attempt to sign in with custom token if available
                        if (initialAuthToken) {
                            await signInWithCustomToken(auth, initialAuthToken);
                        } else {
                            // Fallback to anonymous sign-in
                            const anonUser = await signInAnonymously(auth);
                            userId = anonUser.user.uid;
                        }
                    } catch (error) {
                        console.error("Firebase Auth failed:", error);
                        // If all else fails, use a local random ID (though this should be rare)
                        userId = crypto.randomUUID();
                    }
                }
                isAuthReady = true;
                // Initialization complete
                console.log(`System Initialized. User ID: ${userId}`);
            });
        }
        // --- End Firebase Setup ---

        // --- Core Application Logic (Gemini and Speech API) ---

        // Configuration
        const API_MODEL = 'gemini-2.5-flash-preview-09-2025';
        const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/${API_MODEL}:generateContent?key=`; // Key will be appended by canvas runtime
        const DEFAULT_HINDI_TEXT = '(Your esteemed voice input will appear here after analysis.)';

        // DOM Elements
        const micButton = document.getElementById('mic-button');
        const micPrompt = document.getElementById('mic-prompt');
        const statusDisplay = document.getElementById('status-display');
        const hindiTranscript = document.getElementById('hindi-transcript');
        const englishTranslation = document.getElementById('english-translation');
        const sourcesDisplay = document.getElementById('sources-display');

        // State
        let isRecording = false;
        let recognition = null;
        let recognitionTimeout = null; // To handle recognition ending

        /**
         * Utility function for exponential backoff during API calls.
         * @param {number} attempt The current attempt number.
         * @returns {number} Delay in milliseconds.
         */
        const getDelay = (attempt) => Math.min(1000 * Math.pow(2, attempt), 30000);

        /**
         * Updates the UI status message.
         * @param {string} message The message to display.
         * @param {string} styleClass Tailwind classes for styling (e.g., 'bg-blue-50 text-blue-700').
         */
        function updateStatus(message, styleClass) {
            statusDisplay.textContent = message;
            statusDisplay.className = `p-4 rounded-lg mb-6 border text-center text-sm font-medium transition duration-300 ${styleClass}`;
        }

        /**
         * Clears previous results and prepares the UI for a new request.
         */
        function clearResults() {
            hindiTranscript.innerHTML = DEFAULT_HINDI_TEXT;
            englishTranslation.innerHTML = '(The system\'s high-value, professionally humorous output will be rendered here.)';
            sourcesDisplay.textContent = '';
            sourcesDisplay.classList.add('hidden');
        }

        /**
         * Converts the fetch response to a JSON object.
         * @param {Response} response The fetch response object.
         * @returns {Promise<Object>} The JSON payload.
         */
        async function handleResponse(response) {
            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`API Request failed with status ${response.status}: ${errorText}`);
            }
            return response.json();
        }

        /**
         * Calls the Gemini API to translate and refine the Hindi text.
         * Implements exponential backoff for reliability.
         * @param {string} hindiText The text to be translated.
         */
        async function translateAndRefine(hindiText) {
            updateStatus('Analysis in Progress... Consulting AI Linguistic Sub-processors.', 'bg-yellow-50 text-yellow-700 border-yellow-200');
            englishTranslation.innerHTML = '<i class="fas fa-spinner fa-spin mr-2"></i> Engaging Advanced Translation Protocols...';

            const systemPrompt = `You are a highly professional, yet absurdly formal AI linguistic consultant. Your primary directive is to translate the user's provided Hindi text into English. In your translation, you must subtly introduce a tone of over-engineered sophistication and mock professionalism to make the final output unexpectedly humorous. For example, 'I am hungry' might become 'The current metabolic state indicates a necessity for immediate caloric intake.' Do not mention your role as an AI, translator, or linguistic consultant in the final English output.`;

            const userQuery = `Translate the following Hindi text and apply the refined, sophisticated style:\n\nOriginal Hindi: "${hindiText}"`;

            const payload = {
                contents: [{ parts: [{ text: userQuery }] }],
                systemInstruction: { parts: [{ text: systemPrompt }] },
                tools: [{ "google_search": {} }], // Use Google Search for grounding if needed
            };

            const maxAttempts = 5;
            for (let attempt = 0; attempt < maxAttempts; attempt++) {
                const controller = new AbortController();
                // Set a 20-second timeout for the API call
                const timeoutId = setTimeout(() => controller.abort(), 20000); 

                try {
                    const response = await fetch(API_URL, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload),
                        signal: controller.signal // Apply the abort signal
                    });

                    clearTimeout(timeoutId); // Clear timeout if fetch succeeds

                    const result = await handleResponse(response);
                    const candidate = result.candidates?.[0];

                    if (candidate && candidate.content?.parts?.[0]?.text) {
                        const text = candidate.content.parts[0].text;
                        englishTranslation.textContent = text;
                        updateStatus('Protocol Complete. Translation Verified and Subtly Humorous.', 'bg-green-50 text-green-700 border-green-200');

                        // Handle Grounding Sources (Citations)
                        let sources = [];
                        const groundingMetadata = candidate.groundingMetadata;
                        if (groundingMetadata && groundingMetadata.groundingAttributions) {
                            sources = groundingMetadata.groundingAttributions
                                .map(attribution => ({
                                    uri: attribution.web?.uri,
                                    title: attribution.web?.title,
                                }))
                                .filter(source => source.uri && source.title);
                        }

                        if (sources.length > 0) {
                            sourcesDisplay.classList.remove('hidden');
                            sourcesDisplay.innerHTML = '<p class="font-bold">Operational Data Sources:</p>';
                            sources.forEach((source, index) => {
                                const link = document.createElement('a');
                                link.href = source.uri;
                                link.target = '_blank';
                                link.className = 'source-link';
                                link.textContent = `${source.title} (Source ${index + 1})`;
                                sourcesDisplay.appendChild(link);
                                if (index < sources.length - 1) {
                                    sourcesDisplay.appendChild(document.createTextNode(' | '));
                                }
                            });
                        }

                        return; // Success, exit function
                    } else {
                        throw new Error("API response lacked generated text content.");
                    }

                } catch (error) {
                    clearTimeout(timeoutId); // Clear timeout on error

                    // Check for AbortError (Timeout) and log appropriately
                    if (error.name === 'AbortError') {
                         console.error(`Attempt ${attempt + 1} failed: Network timeout (20s) reached.`);
                    } else {
                        console.error(`Attempt ${attempt + 1} failed:`, error);
                    }

                    if (attempt < maxAttempts - 1) {
                        // Wait and retry
                        await new Promise(resolve => setTimeout(resolve, getDelay(attempt)));
                    } else {
                        // Final failure after all attempts
                        updateStatus('CRITICAL FAILURE: Translation Module Overload. Please Retry.', 'bg-red-100 text-red-700 border-red-300');
                        englishTranslation.textContent = 'ERROR: The system has encountered an unexpected semantic dissonance and failed to produce a refined statement.';
                        return;
                    }
                }
            }
        }

        /**
         * Initializes and starts the Speech Recognition service.
         */
        function startRecognition() {
            clearResults();
            sourcesDisplay.classList.add('hidden'); // Ensure sources are hidden at start

            // Check for Speech Recognition API support
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                updateStatus('SYSTEM ERROR: Browser Speech Input Module Not Found. Please use Chrome/Edge.', 'bg-red-100 text-red-700 border-red-300');
                micButton.disabled = true;
                return;
            }

            // Initialize Recognition Object
            recognition = new SpeechRecognition();
            recognition.continuous = false; // Stop after a single phrase
            recognition.lang = 'hi-IN'; // Set language to Hindi
            recognition.interimResults = false; // Only deliver final results

            // --- Event Handlers ---

            recognition.onstart = () => {
                isRecording = true;
                micButton.classList.add('recording');
                micPrompt.textContent = 'RECORDING... Please Articulate Clearly in Hindi.';
                updateStatus('Recording Active. Listening for High-Value Input...', 'bg-red-100 text-red-700 border-red-300');
                // Set a timeout to stop recording automatically after max duration (e.g., 10 seconds)
                recognitionTimeout = setTimeout(() => {
                    recognition.stop();
                }, 10000);
            };

            recognition.onresult = (event) => {
                clearTimeout(recognitionTimeout);
                
                // Get the final transcript
                const transcript = event.results[0][0].transcript;
                hindiTranscript.textContent = transcript;
                
                updateStatus('Audio Received. Commencing Linguistic Analysis.', 'bg-indigo-100 text-indigo-700 border-indigo-300');

                // Pass the Hindi transcript to the Gemini API for translation and refinement
                translateAndRefine(transcript);
            };

            recognition.onend = () => {
                clearTimeout(recognitionTimeout);
                isRecording = false;
                micButton.classList.remove('recording');
                micPrompt.textContent = 'Click to Initiate Audio Protocol';

                // Only update status if the transcript is still the default, meaning no speech was successfully captured/processed
                if (hindiTranscript.textContent === DEFAULT_HINDI_TEXT) {
                    updateStatus('Recording Ended. No Transcript Detected. Please Speak Clearly.', 'bg-gray-100 text-gray-700 border-gray-300');
                }
            };

            recognition.onerror = (event) => {
                clearTimeout(recognitionTimeout);
                isRecording = false;
                micButton.classList.remove('recording');
                micPrompt.textContent = 'Click to Initiate Audio Protocol';
                console.error('Speech Recognition Error:', event.error);
                
                // CRITICAL NOTE: The user must grant permission.
                let errorMessage = `ACCESS DENIED or ERROR: ${event.error}. Please ensure microphone access is explicitly enabled for this page and try again.`;
                if (event.error === 'not-allowed') {
                    errorMessage = 'PERMISSION DENIED: Microphone access was blocked. Please check your browser settings and reload the page.';
                }
                
                updateStatus(errorMessage, 'bg-red-100 text-red-700 border-red-300');
            };

            // Start the recognition
            try {
                recognition.start();
            } catch (e) {
                console.error("Recognition start failed:", e);
                updateStatus('SYSTEM ERROR: Could not initiate microphone access.', 'bg-red-100 text-red-700 border-red-300');
            }
        }

        /**
         * Event listener for the main microphone button.
         */
        micButton.addEventListener('click', () => {
            if (isRecording) {
                // If currently recording, stop it immediately
                if (recognition) {
                    clearTimeout(recognitionTimeout);
                    recognition.stop();
                }
            } else {
                // If not recording, start the process
                startRecognition();
            }
        });
    </script>
</div>
